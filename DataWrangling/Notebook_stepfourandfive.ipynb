{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cf5CmXQCZyF1"
   },
   "source": [
    "# Guided Capstone Step 4. Pre-Processing and Training Data Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2jue2jPGJlt"
   },
   "source": [
    "**The Data Science Method**  \n",
    "\n",
    "\n",
    "1.   Problem Identification \n",
    "\n",
    "\n",
    "2.   Data Wrangling \n",
    "  \n",
    " \n",
    "3.   Exploratory Data Analysis   \n",
    "\n",
    "4.   **Pre-processing and Training Data Development**  \n",
    " * Create dummy or indicator features for categorical variables\n",
    "  * Standardize the magnitude of numeric features\n",
    "  * Split into testing and training datasets\n",
    "  * Apply scaler to the testing set\n",
    "5.   Modeling \n",
    "  * Fit Models with Training Data Set\n",
    "  * Review Model Outcomes — Iterate over additional models as needed.\n",
    "  * Identify the Final Model\n",
    "\n",
    "6.   Documentation\n",
    "  * Review the Results\n",
    "  * Present and share your findings - storytelling\n",
    "  * Finalize Code \n",
    "  * Finalize Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8xfkAqqZyF2"
   },
   "source": [
    "**<font color='teal'> Start by loading the necessary packages as we did in step 3 and printing out our current working directory just to confirm we are in the correct project directory. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ry6WPL5eZyF3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Shalin\\\\Springboard bootcamp\\\\projects\\\\Guided Capstone project 1'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'data',\n",
       " 'figures',\n",
       " 'GuidedCapstoneStep3HL.ipynb',\n",
       " 'GuidedCapstoneStep4 and step5HL.ipynb',\n",
       " 'GuidedCapstoneStep6HL.ipynb',\n",
       " 'GuidedCapstone_Step2HL.ipynb',\n",
       " 'models',\n",
       " 'Step 1 -Problem Identification',\n",
       " 'Step 2 - Data Wrangling',\n",
       " 'Step 3 - EDA',\n",
       " 'Step 4 - Data preprocessing and training data development',\n",
       " 'Step 5 - Modeling',\n",
       " 'Step 6 - Documentation',\n",
       " 'updated_ski_data.csv']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "630T-ogRZyF8"
   },
   "source": [
    "**<font color='teal'>  Load the csv file you created in step 3, remember it should be saved inside your data subfolder and print the first five rows.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMNbk0u3ZyF9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>state</th>\n",
       "      <th>summit_elev</th>\n",
       "      <th>vertical_drop</th>\n",
       "      <th>trams</th>\n",
       "      <th>fastEight</th>\n",
       "      <th>fastSixes</th>\n",
       "      <th>fastQuads</th>\n",
       "      <th>quad</th>\n",
       "      <th>triple</th>\n",
       "      <th>...</th>\n",
       "      <th>SkiableTerrain_ac</th>\n",
       "      <th>Snow Making_ac</th>\n",
       "      <th>daysOpenLastYear</th>\n",
       "      <th>yearsOpen</th>\n",
       "      <th>averageSnowfall</th>\n",
       "      <th>AdultWeekday</th>\n",
       "      <th>AdultWeekend</th>\n",
       "      <th>projectedDaysOpen</th>\n",
       "      <th>NightSkiing_ac</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eaglecrest Ski Area</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2600</td>\n",
       "      <td>1540</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>640.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>53.00000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hilltop Ski Area</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2090</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>34.00000</td>\n",
       "      <td>152.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sunrise Park Resort</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>11100</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>800.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>78.00000</td>\n",
       "      <td>104.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yosemite Ski &amp; Snowboard Area</td>\n",
       "      <td>California</td>\n",
       "      <td>7800</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bear Mountain</td>\n",
       "      <td>California</td>\n",
       "      <td>8805</td>\n",
       "      <td>1665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>198.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>57.916957</td>\n",
       "      <td>64.16681</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name       state  summit_elev  vertical_drop  \\\n",
       "0            Eaglecrest Ski Area      Alaska         2600           1540   \n",
       "1               Hilltop Ski Area      Alaska         2090            294   \n",
       "2            Sunrise Park Resort     Arizona        11100           1800   \n",
       "3  Yosemite Ski & Snowboard Area  California         7800            600   \n",
       "4                  Bear Mountain  California         8805           1665   \n",
       "\n",
       "   trams  fastEight  fastSixes  fastQuads  quad  triple  ...  \\\n",
       "0      0        0.0          0          0     0       0  ...   \n",
       "1      0        0.0          0          0     0       1  ...   \n",
       "2      0        0.0          0          1     2       3  ...   \n",
       "3      0        0.0          0          0     0       1  ...   \n",
       "4      0        0.0          0          2     1       2  ...   \n",
       "\n",
       "   SkiableTerrain_ac  Snow Making_ac  daysOpenLastYear  yearsOpen  \\\n",
       "0              640.0            60.0              45.0       44.0   \n",
       "1               30.0            30.0             150.0       36.0   \n",
       "2              800.0            80.0             115.0       49.0   \n",
       "3               88.0             0.0             110.0       84.0   \n",
       "4              198.0           198.0             122.0       76.0   \n",
       "\n",
       "   averageSnowfall  AdultWeekday  AdultWeekend  projectedDaysOpen  \\\n",
       "0            350.0     47.000000      53.00000               90.0   \n",
       "1             69.0     30.000000      34.00000              152.0   \n",
       "2            250.0     74.000000      78.00000              104.0   \n",
       "3            300.0     47.000000      47.00000              107.0   \n",
       "4            100.0     57.916957      64.16681              130.0   \n",
       "\n",
       "   NightSkiing_ac  clusters  \n",
       "0             0.0         0  \n",
       "1            30.0         0  \n",
       "2            80.0         1  \n",
       "3             0.0         2  \n",
       "4             0.0         1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'C:\\\\Shalin\\\\Springboard bootcamp\\\\projects\\\\Guided Capstone project 1\\\\data\\\\step3_output.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkBHf9smZyGB"
   },
   "source": [
    "## Create dummy features for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWKHm0NhAnrJ"
   },
   "source": [
    "**<font color='teal'> Create dummy variables for `state`. Add the dummies back to the dataframe and remove the original column for `state`. </font>**\n",
    "\n",
    "Hint: you can see an example of how to execute this in Aiden's article on preprocessing [here](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-pre-processing-and-training-data-development-fd2d75182967). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                  object\n",
       "state                 object\n",
       "summit_elev            int64\n",
       "vertical_drop          int64\n",
       "trams                  int64\n",
       "fastEight            float64\n",
       "fastSixes              int64\n",
       "fastQuads              int64\n",
       "quad                   int64\n",
       "triple                 int64\n",
       "double                 int64\n",
       "surface                int64\n",
       "total_chairs           int64\n",
       "Runs                 float64\n",
       "TerrainParks         float64\n",
       "LongestRun_mi        float64\n",
       "SkiableTerrain_ac    float64\n",
       "Snow Making_ac       float64\n",
       "daysOpenLastYear     float64\n",
       "yearsOpen            float64\n",
       "averageSnowfall      float64\n",
       "AdultWeekday         float64\n",
       "AdultWeekend         float64\n",
       "projectedDaysOpen    float64\n",
       "NightSkiing_ac       float64\n",
       "clusters               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZqWk8ltZyGZ"
   },
   "outputs": [],
   "source": [
    "dfo=df.select_dtypes(include=['object']) # select object type columns\n",
    "df = pd.concat([df.drop(dfo, axis=1), pd.get_dummies(dfo)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['summit_elev', 'vertical_drop', 'trams', 'fastEight', 'fastSixes',\n",
       "       'fastQuads', 'quad', 'triple', 'double', 'surface',\n",
       "       ...\n",
       "       'state_Rhode Island', 'state_South Dakota', 'state_Tennessee',\n",
       "       'state_Utah', 'state_Vermont', 'state_Virginia', 'state_Washington',\n",
       "       'state_West Virginia', 'state_Wisconsin', 'state_Wyoming'],\n",
       "      dtype='object', length=329)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 329)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnDVhE1-ZyGF"
   },
   "source": [
    "## Standardize the magnitude of numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gW3D-WlDZyGG"
   },
   "source": [
    "**<font color='teal'> Using sklearn preprocessing standardize the scale of the features of the dataframe except the name of the resort which we done't need in the dataframe for modeling, so it can be droppped here as well. Also, we want to hold out our response variable(s) so we can have their true values available for model performance review. Let's set `AdultWeekend` to the y variable as our response for scaling and modeling. Later we will go back and consider the `AdultWeekday`, `dayOpenLastYear`, and `projectedDaysOpen`. For now leave them in the development dataframe. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['summit_elev', 'vertical_drop', 'trams', 'fastEight', 'fastSixes',\n",
       "       'fastQuads', 'quad', 'triple', 'double', 'surface', 'total_chairs',\n",
       "       'Runs', 'TerrainParks', 'LongestRun_mi', 'SkiableTerrain_ac',\n",
       "       'Snow Making_ac', 'daysOpenLastYear', 'yearsOpen', 'averageSnowfall',\n",
       "       'AdultWeekday', 'AdultWeekend', 'projectedDaysOpen', 'NightSkiing_ac',\n",
       "       'clusters', 'state_Alaska', 'state_Arizona', 'state_California',\n",
       "       'state_Colorado', 'state_Connecticut', 'state_Idaho', 'state_Illinois',\n",
       "       'state_Indiana', 'state_Iowa', 'state_Maine', 'state_Maryland',\n",
       "       'state_Massachusetts', 'state_Michigan', 'state_Minnesota',\n",
       "       'state_Missouri', 'state_Montana', 'state_Nevada',\n",
       "       'state_New Hampshire', 'state_New Jersey', 'state_New Mexico',\n",
       "       'state_New York', 'state_North Carolina', 'state_Ohio', 'state_Oregon',\n",
       "       'state_Pennsylvania', 'state_Rhode Island', 'state_South Dakota',\n",
       "       'state_Tennessee', 'state_Utah', 'state_Vermont', 'state_Virginia',\n",
       "       'state_Washington', 'state_West Virginia', 'state_Wisconsin',\n",
       "       'state_Wyoming'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[:,~df.columns.str.startswith('Name')]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZL-q-KtAYI6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gosal\\Anaconda3_2\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\gosal\\Anaconda3_2\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# first we import the preprocessing package from the sklearn library\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name' and 'AdultWeekend' from the df\n",
    "X = df.drop(['AdultWeekend'], axis = 1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the AdultWeekend column of the df \n",
    "y = df['AdultWeekend'] \n",
    "\n",
    "# Here we use the StandardScaler() method of the preprocessing package, and then call the fit() method with parameter X \n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "\n",
    "# Declare a variable called X_scaled, and assign it the result of calling the transform() method with parameter X \n",
    "X_scaled=scaler.transform(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 58)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GAT8h4_mZyGK"
   },
   "source": [
    "## Split into training and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6rdS8EGeAnrW"
   },
   "source": [
    "**<font color='teal'> Using sklearn model selection import train_test_split, and create a 75/25 split with the y = `AdultWeekend`. We will start by using the adult weekend ticket price as our response variable for modeling.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSkPut0gguds"
   },
   "outputs": [],
   "source": [
    "# Import the train_test_split function from the sklearn.model_selection utility.  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get the 1-dimensional flattened array of our response variable y by calling the ravel() function on y\n",
    "y = y.ravel()\n",
    "\n",
    "# Call the train_test_split() function with the first two parameters set to X_scaled and y \n",
    "# Declare four variables, X_train, X_test, y_train and y_test separated by commas \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 58)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 58)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UayqbwkWAnra"
   },
   "source": [
    "Here we start the actual modeling work. First let's fit a multiple linear regression model to predict the `AdultWeekend` price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "83fkLldXFCNd"
   },
   "source": [
    "# Guided Capstone Step 5. Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbZXsVevfr9M"
   },
   "source": [
    "This is the fifth step in the Data Science Method. In the previous steps you cleaned and prepared the datasets. Now it's time to get into the most exciting part: modeling! In this exercise, you'll build three different models and compare each model's performance. In the end, you'll choose the best model for demonstrating insights to Big Mountain management.\n",
    "\n",
    "\n",
    "\n",
    "### **The Data Science Method**  \n",
    "\n",
    "\n",
    "1.   Problem Identification \n",
    "\n",
    "2.   Data Wrangling \n",
    "  \n",
    "3.   Exploratory Data Analysis \n",
    " \n",
    "4.   Pre-processing and Training Data Development\n",
    "\n",
    "5.   **Modeling**\n",
    "  * Fit Models with Training Data Set\n",
    "  * Review Model Outcomes — Iterate over additional models as needed.\n",
    "  * Identify the Final Model\n",
    "\n",
    "6.   Documentation\n",
    "  * Review the Results\n",
    "  * Present and share your findings - storytelling\n",
    "  * Finalize Code \n",
    "  * Finalize Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D_wfsP_-Anra"
   },
   "source": [
    "## Fit Models with a Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CoI8S5SwAnrc"
   },
   "source": [
    "**<font color='teal'> Using sklearn, fit the model on your training dataset.</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_GFr8sRAnrd"
   },
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fW6K7uOPAnre"
   },
   "outputs": [],
   "source": [
    "#Linear Regresion model\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import explained_variance_score,mean_absolute_error\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1fHqz9-WAnrg"
   },
   "source": [
    "**<font color='teal'> Predict on the testing dataset and score the model performance with the y_test set and the y-pred values. The explained variance is a measure of the variation explained by the model. This is also known as the R-squared value. </font>**\n",
    "\n",
    "Hint: you will have to use the `predict()` method here as it's used in this [DSM article](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-modeling-56b4233cad1b) about modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIo01lFEAnrh"
   },
   "outputs": [],
   "source": [
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.48727815236312"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N4YS0WE2Anrk"
   },
   "source": [
    "## Review Model Outcomes — Iterate over additional models as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSh9sGIYAnrk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7367255858069923"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You might want to use the explained_variance_score() and mean_absolute_error() metrics.\n",
    "# To do so, you will need to import them from sklearn.metrics. \n",
    "# You can plug y_test and y_pred into the functions to evaluate the model\n",
    "from sklearn.metrics import explained_variance_score\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "evs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihzeo8tqAnro"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.667547731169333"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWJcOuSdAnrr"
   },
   "source": [
    "**<font color='teal'> Print the intercept value from the linear model. </font>**\n",
    "\n",
    "Hint: our linear regression model `lm` has an attribute `intercept_` for the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WzWejn6Anrt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.861283752792438"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edajrenAAnrv"
   },
   "source": [
    "**<font color='teal'> The intercept is the mean `AdultWeekend` price for all the resorts given the other characteristics. The addition or subtraction of each of the coefficient values in the regression are numeric adjustments applied to the intercept to provide a particular observation's value for the resulting `AdultWeekend` value. Also, because we took the time to scale our x values in the training data, we can compare each of the coeeficients for the features to determine the feature importances. Print the coefficient values from the linear model and sort in descending order to identify the top ten most important features.</font>** \n",
    "\n",
    "\n",
    "Hint: make sure to review the absolute value of the coefficients, because the adjustment may be positive or negative, but what we are looking for is the magnitude of impact on our response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FEKc_lmZAnrw",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state_Tennessee</th>\n",
       "      <td>1.882277e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_North Carolina</th>\n",
       "      <td>1.521682e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_New Mexico</th>\n",
       "      <td>1.252487e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Montana</th>\n",
       "      <td>1.167195e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Massachusetts</th>\n",
       "      <td>1.021386e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Maryland</th>\n",
       "      <td>9.431548e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Arizona</th>\n",
       "      <td>9.089298e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Nevada</th>\n",
       "      <td>8.779054e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Virginia</th>\n",
       "      <td>8.549212e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Ohio</th>\n",
       "      <td>8.197452e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Idaho</th>\n",
       "      <td>8.066485e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Rhode Island</th>\n",
       "      <td>7.829260e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_New Jersey</th>\n",
       "      <td>7.211811e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Colorado</th>\n",
       "      <td>7.036637e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_South Dakota</th>\n",
       "      <td>6.797341e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Connecticut</th>\n",
       "      <td>5.905158e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Maine</th>\n",
       "      <td>5.674133e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Indiana</th>\n",
       "      <td>5.324482e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Minnesota</th>\n",
       "      <td>5.080584e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Pennsylvania</th>\n",
       "      <td>5.060416e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Oregon</th>\n",
       "      <td>4.716017e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_West Virginia</th>\n",
       "      <td>4.209765e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Alaska</th>\n",
       "      <td>4.199715e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Illinois</th>\n",
       "      <td>4.150238e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Wyoming</th>\n",
       "      <td>3.998830e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_New Hampshire</th>\n",
       "      <td>3.452679e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_California</th>\n",
       "      <td>2.838173e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Iowa</th>\n",
       "      <td>2.669371e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Utah</th>\n",
       "      <td>2.645268e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Michigan</th>\n",
       "      <td>1.959789e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clusters</th>\n",
       "      <td>1.924751e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Missouri</th>\n",
       "      <td>1.685099e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Vermont</th>\n",
       "      <td>1.498877e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Washington</th>\n",
       "      <td>1.297573e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdultWeekday</th>\n",
       "      <td>6.973865e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface</th>\n",
       "      <td>6.960798e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quad</th>\n",
       "      <td>6.679577e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Wisconsin</th>\n",
       "      <td>6.106197e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triple</th>\n",
       "      <td>5.978863e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TerrainParks</th>\n",
       "      <td>5.180097e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_chairs</th>\n",
       "      <td>3.987214e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_New York</th>\n",
       "      <td>3.683820e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LongestRun_mi</th>\n",
       "      <td>3.232445e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastQuads</th>\n",
       "      <td>1.047226e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Runs</th>\n",
       "      <td>7.979604e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>double</th>\n",
       "      <td>6.632028e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearsOpen</th>\n",
       "      <td>4.144968e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daysOpenLastYear</th>\n",
       "      <td>1.551197e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projectedDaysOpen</th>\n",
       "      <td>1.203200e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow Making_ac</th>\n",
       "      <td>7.877843e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NightSkiing_ac</th>\n",
       "      <td>6.489663e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkiableTerrain_ac</th>\n",
       "      <td>3.168536e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vertical_drop</th>\n",
       "      <td>2.953801e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summit_elev</th>\n",
       "      <td>6.941656e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>averageSnowfall</th>\n",
       "      <td>1.910383e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastEight</th>\n",
       "      <td>1.470558e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trams</th>\n",
       "      <td>1.158698e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastSixes</th>\n",
       "      <td>6.525891e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Coefficient\n",
       "state_Tennessee       1.882277e+01\n",
       "state_North Carolina  1.521682e+01\n",
       "state_New Mexico      1.252487e+01\n",
       "state_Montana         1.167195e+01\n",
       "state_Massachusetts   1.021386e+01\n",
       "state_Maryland        9.431548e+00\n",
       "state_Arizona         9.089298e+00\n",
       "state_Nevada          8.779054e+00\n",
       "state_Virginia        8.549212e+00\n",
       "state_Ohio            8.197452e+00\n",
       "state_Idaho           8.066485e+00\n",
       "state_Rhode Island    7.829260e+00\n",
       "state_New Jersey      7.211811e+00\n",
       "state_Colorado        7.036637e+00\n",
       "state_South Dakota    6.797341e+00\n",
       "state_Connecticut     5.905158e+00\n",
       "state_Maine           5.674133e+00\n",
       "state_Indiana         5.324482e+00\n",
       "state_Minnesota       5.080584e+00\n",
       "state_Pennsylvania    5.060416e+00\n",
       "state_Oregon          4.716017e+00\n",
       "state_West Virginia   4.209765e+00\n",
       "state_Alaska          4.199715e+00\n",
       "state_Illinois        4.150238e+00\n",
       "state_Wyoming         3.998830e+00\n",
       "state_New Hampshire   3.452679e+00\n",
       "state_California      2.838173e+00\n",
       "state_Iowa            2.669371e+00\n",
       "state_Utah            2.645268e+00\n",
       "state_Michigan        1.959789e+00\n",
       "clusters              1.924751e+00\n",
       "state_Missouri        1.685099e+00\n",
       "state_Vermont         1.498877e+00\n",
       "state_Washington      1.297573e+00\n",
       "AdultWeekday          6.973865e-01\n",
       "surface               6.960798e-01\n",
       "quad                  6.679577e-01\n",
       "state_Wisconsin       6.106197e-01\n",
       "triple                5.978863e-01\n",
       "TerrainParks          5.180097e-01\n",
       "total_chairs          3.987214e-01\n",
       "state_New York        3.683820e-01\n",
       "LongestRun_mi         3.232445e-01\n",
       "fastQuads             1.047226e-01\n",
       "Runs                  7.979604e-02\n",
       "double                6.632028e-02\n",
       "yearsOpen             4.144968e-02\n",
       "daysOpenLastYear      1.551197e-02\n",
       "projectedDaysOpen     1.203200e-02\n",
       "Snow Making_ac        7.877843e-03\n",
       "NightSkiing_ac        6.489663e-03\n",
       "SkiableTerrain_ac     3.168536e-03\n",
       "vertical_drop         2.953801e-03\n",
       "summit_elev           6.941656e-04\n",
       "averageSnowfall       1.910383e-04\n",
       "fastEight             1.470558e-11\n",
       "trams                 1.158698e-11\n",
       "fastSixes             6.525891e-13"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You might want to make a pandas DataFrame displaying the coefficients for each state like so: \n",
    "pd.DataFrame(abs(lm.coef_), X.columns, columns=['Coefficient']).sort_values(by = ['Coefficient'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BpdALMoAAnry"
   },
   "source": [
    "**<font color='teal'>You should see that the top ten important features are different states. However, the state is not something the managers at the Big Mountain Resort can do anything about. Given that we care more about actionable traits associated with ticket pricing, rebuild the model without the state features and compare the results. </font>**\n",
    "\n",
    "Hint: Try to construct another model using exactly the steps we followed above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-mHYA1BzAnrz"
   },
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pz1YXAdiAnr0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 23)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuid model without the 'state' columns\n",
    "X_train_2= X_train.loc[:,~X_train.columns.str.startswith('state')]\n",
    "X_test_2= X_test.loc[:,~X_test.columns.str.startswith('state')]\n",
    "X_train_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 23)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Linear Regresion model on the updated dataframe without state columns\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import explained_variance_score,mean_absolute_error\n",
    "lm = linear_model.LinearRegression()\n",
    "model_2 = lm.fit(X_train_2,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='teal'> Predict on the testing dataset and score the model performance with the y_test set and the y-pred values. The explained variance is a measure of the variation explained by the model. This is also known as the R-squared value. </font>**\n",
    "\n",
    "Hint: you will have to use the `predict()` method here as it's used in this [DSM article](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-modeling-56b4233cad1b) about modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nM1EGf16Anr2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 93.03581079,  81.6768078 ,  43.20081347,  38.66125619,\n",
       "        56.20004579,  46.72161959,  72.24454629, 107.1517422 ,\n",
       "        59.36383068,  49.78297577,  67.31212032,  75.95798632,\n",
       "        44.30818999,  73.10188805,  56.24942764,  57.81538451,\n",
       "        59.70356497,  56.27030526,  51.80825747,  77.01804426,\n",
       "        38.47648064,  61.51064714,  46.75196896,  56.288816  ,\n",
       "        54.36331561,  78.30889861,  90.26668035,  54.26942107,\n",
       "        52.09940242,  55.6180931 ,  62.51343739,  43.7722026 ,\n",
       "        59.55666238,  60.92939484,  52.84090187,  81.9049391 ,\n",
       "        44.84809082,  28.93022776,  72.45739036,  46.20674573,\n",
       "        62.87068072,  63.49185123,  44.21483085,  75.88252926,\n",
       "        68.7553718 ,  74.58271908,  87.70115219,  50.69718125,\n",
       "        82.08501166,  48.62659301,  46.3991855 ,  61.34046781,\n",
       "        39.02240248,  50.80633453,  90.03927303,  60.84888209,\n",
       "        42.20201808,  67.1359272 ,  91.22542859,  76.0441241 ,\n",
       "        36.42393865,  56.07107099,  52.53001732,  64.92299254,\n",
       "        87.86318246,  94.49756133,  61.0660765 ,  65.0512791 ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a variable called y_pred_2 and assign it the result of calling predict() on our model variable with parameter X_test_2\n",
    "y_pred_2 = lm.predict(X_test_2)\n",
    "y_pred_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Model Outcomes — Iterate over additional models as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7596580348808419"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You might want to use the explained_variance_score() and mean_absolute_error() metrics.\n",
    "# To do so, you will need to import them from sklearn.metrics. \n",
    "# You can plug y_test and y_pred into the functions to evaluate the model\n",
    "from sklearn.metrics import explained_variance_score\n",
    "evs_2 = explained_variance_score(y_test, y_pred_2)\n",
    "evs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.613244205230069"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae_2 = mean_absolute_error(y_test, y_pred_2)\n",
    "mae_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the coefficient values from the linear model and sort in descending order to identify the top ten most important features.</font>** \n",
    "\n",
    "Hint: make sure to review the absolute value of the coefficients, because the adjustment may be positive or negative, but what we are looking for is the magnitude of impact on our response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clusters</th>\n",
       "      <td>2.925300e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quad</th>\n",
       "      <td>8.944225e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdultWeekday</th>\n",
       "      <td>7.216113e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface</th>\n",
       "      <td>6.595900e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TerrainParks</th>\n",
       "      <td>4.798342e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_chairs</th>\n",
       "      <td>4.759169e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triple</th>\n",
       "      <td>3.588631e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>double</th>\n",
       "      <td>2.447261e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastQuads</th>\n",
       "      <td>1.269474e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Runs</th>\n",
       "      <td>4.230506e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LongestRun_mi</th>\n",
       "      <td>3.313352e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearsOpen</th>\n",
       "      <td>2.941888e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daysOpenLastYear</th>\n",
       "      <td>2.126885e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projectedDaysOpen</th>\n",
       "      <td>8.708788e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NightSkiing_ac</th>\n",
       "      <td>8.111249e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow Making_ac</th>\n",
       "      <td>4.745888e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vertical_drop</th>\n",
       "      <td>4.600389e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkiableTerrain_ac</th>\n",
       "      <td>4.246379e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>averageSnowfall</th>\n",
       "      <td>2.869571e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summit_elev</th>\n",
       "      <td>4.702551e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trams</th>\n",
       "      <td>4.565792e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastEight</th>\n",
       "      <td>3.046174e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastSixes</th>\n",
       "      <td>1.110223e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Coefficient\n",
       "clusters           2.925300e+00\n",
       "quad               8.944225e-01\n",
       "AdultWeekday       7.216113e-01\n",
       "surface            6.595900e-01\n",
       "TerrainParks       4.798342e-01\n",
       "total_chairs       4.759169e-01\n",
       "triple             3.588631e-01\n",
       "double             2.447261e-01\n",
       "fastQuads          1.269474e-01\n",
       "Runs               4.230506e-02\n",
       "LongestRun_mi      3.313352e-02\n",
       "yearsOpen          2.941888e-02\n",
       "daysOpenLastYear   2.126885e-02\n",
       "projectedDaysOpen  8.708788e-03\n",
       "NightSkiing_ac     8.111249e-03\n",
       "Snow Making_ac     4.745888e-03\n",
       "vertical_drop      4.600389e-03\n",
       "SkiableTerrain_ac  4.246379e-03\n",
       "averageSnowfall    2.869571e-03\n",
       "summit_elev        4.702551e-05\n",
       "trams              4.565792e-15\n",
       "fastEight          3.046174e-15\n",
       "fastSixes          1.110223e-15"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You might want to make a pandas DataFrame displaying the coefficients for each state like so: \n",
    "pd.DataFrame(abs(lm.coef_), X_train_2.columns, columns=['Coefficient']).sort_values(by = ['Coefficient'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JWjQLr3LAnr6"
   },
   "source": [
    "**<font color='teal'> When reviewing our new model coefficients, we see `summit_elev` is now in the number two spot. This is also difficult to change from a management prespective and highly correlated with `base_elev` and `vertical_drop`.  This time, rebuild the model without the state features and without the `summit_elev` and without `base_elev`and compare the results. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXqvcn93Anr7"
   },
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6eugnDNNAnr8"
   },
   "outputs": [],
   "source": [
    "# Rebuid model without the 'summit_elev' and 'base_elev' columns\n",
    "X_train_3 = X_train_2.drop(columns = ['summit_elev'], axis = 1)\n",
    "#X_train_3= X_train_2.loc[:,~X_train_2.columns.str.startswith('summit_')]\n",
    "X_test_3 = X_test_2.drop(columns = ['summit_elev'], axis = 1)\n",
    "#X_train_3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pq0pW7G9Anr_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 22)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 22)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "reXlf0HAAnsG"
   },
   "outputs": [],
   "source": [
    "#Apply Linear Regresion model on the updated dataframe without state and summit_elev columns\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import explained_variance_score,mean_absolute_error\n",
    "lm = linear_model.LinearRegression()\n",
    "model_3 = lm.fit(X_train_3,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 93.08635581,  81.61118183,  43.2448648 ,  38.64372189,\n",
       "        56.37976554,  46.82155572,  72.33385807, 106.77733025,\n",
       "        59.51045661,  49.78637248,  67.19469494,  75.98778   ,\n",
       "        44.40509341,  73.305256  ,  56.43044729,  57.99179097,\n",
       "        59.77030067,  56.24377213,  51.82348566,  76.95758434,\n",
       "        38.48247528,  61.49570346,  46.74222179,  56.34044943,\n",
       "        54.31435896,  78.3099563 ,  90.20394279,  54.21666904,\n",
       "        52.08600595,  55.5835149 ,  62.47294138,  43.73599157,\n",
       "        59.55408438,  60.90860372,  52.81144059,  81.86450152,\n",
       "        44.85375917,  28.93344415,  72.65851271,  46.19147134,\n",
       "        62.83485916,  63.50054401,  44.22948991,  76.06489619,\n",
       "        68.73987235,  74.55898902,  87.58423156,  50.64339507,\n",
       "        82.29025576,  48.58901454,  46.35828182,  61.33120715,\n",
       "        39.00916257,  50.73884408,  90.09416423,  60.79765503,\n",
       "        42.22614939,  67.07634376,  91.39688212,  76.04391152,\n",
       "        36.41018213,  56.12648074,  52.52135964,  64.91559385,\n",
       "        87.72627038,  94.4475196 ,  61.01817017,  65.02458188])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a variable called y_pred_3 and assign it the result of calling predict() on our model variable with parameter X_test_3\n",
    "y_pred_3 = lm.predict(X_test_3)\n",
    "y_pred_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Model Outcomes — Iterate over additional models as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7587871534763161"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You might want to use the explained_variance_score() and mean_absolute_error() metrics.\n",
    "# To do so, you will need to import them from sklearn.metrics. \n",
    "# You can plug y_test and y_pred into the functions to evaluate the model\n",
    "from sklearn.metrics import explained_variance_score\n",
    "evs_3 = explained_variance_score(y_test, y_pred_3)\n",
    "evs_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.629743096594611"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae_3 = mean_absolute_error(y_test, y_pred_3)\n",
    "mae_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the coefficient values from the linear model and sort in descending order to identify the top ten most important features.</font>** \n",
    "\n",
    "Hint: make sure to review the absolute value of the coefficients, because the adjustment may be positive or negative, but what we are looking for is the magnitude of impact on our response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clusters</th>\n",
       "      <td>3.021642e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quad</th>\n",
       "      <td>8.989091e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdultWeekday</th>\n",
       "      <td>7.208570e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface</th>\n",
       "      <td>6.587074e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TerrainParks</th>\n",
       "      <td>4.823240e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_chairs</th>\n",
       "      <td>4.807072e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triple</th>\n",
       "      <td>3.523301e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>double</th>\n",
       "      <td>2.456042e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastQuads</th>\n",
       "      <td>1.337796e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Runs</th>\n",
       "      <td>4.163455e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LongestRun_mi</th>\n",
       "      <td>3.706933e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearsOpen</th>\n",
       "      <td>2.948717e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daysOpenLastYear</th>\n",
       "      <td>2.101642e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projectedDaysOpen</th>\n",
       "      <td>8.538269e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NightSkiing_ac</th>\n",
       "      <td>8.305197e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow Making_ac</th>\n",
       "      <td>4.618653e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vertical_drop</th>\n",
       "      <td>4.556349e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkiableTerrain_ac</th>\n",
       "      <td>4.271081e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>averageSnowfall</th>\n",
       "      <td>2.972488e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trams</th>\n",
       "      <td>7.299716e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastSixes</th>\n",
       "      <td>3.830269e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastEight</th>\n",
       "      <td>1.415534e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Coefficient\n",
       "clusters           3.021642e+00\n",
       "quad               8.989091e-01\n",
       "AdultWeekday       7.208570e-01\n",
       "surface            6.587074e-01\n",
       "TerrainParks       4.823240e-01\n",
       "total_chairs       4.807072e-01\n",
       "triple             3.523301e-01\n",
       "double             2.456042e-01\n",
       "fastQuads          1.337796e-01\n",
       "Runs               4.163455e-02\n",
       "LongestRun_mi      3.706933e-02\n",
       "yearsOpen          2.948717e-02\n",
       "daysOpenLastYear   2.101642e-02\n",
       "projectedDaysOpen  8.538269e-03\n",
       "NightSkiing_ac     8.305197e-03\n",
       "Snow Making_ac     4.618653e-03\n",
       "vertical_drop      4.556349e-03\n",
       "SkiableTerrain_ac  4.271081e-03\n",
       "averageSnowfall    2.972488e-03\n",
       "trams              7.299716e-15\n",
       "fastSixes          3.830269e-15\n",
       "fastEight          1.415534e-15"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You might want to make a pandas DataFrame displaying the coefficients for each state like so: \n",
    "pd.DataFrame(abs(lm.coef_), X_train_3.columns, columns=['Coefficient']).sort_values(by = ['Coefficient'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJvQMns6AnsI"
   },
   "source": [
    "## Identify the Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LD7-3iLcAnsK"
   },
   "source": [
    "**<font color='teal'> Review the model performances in the table below and choose the best model for proving insights to Big Mountain management about what features are driving ski resort lift ticket prices. Type your choice in the final markdown cell — you will discuss this selection more in the next step of the guided casptone. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2c-zn7TAnsL"
   },
   "source": [
    "Model Selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgC0eMBrAnsM"
   },
   "source": [
    "| Model            | Explained Variance| Mean Absolute Error|Features Dropped                 |\n",
    "| -----------------|-------------------|--------------------|---------------------------------|                    \n",
    "| Model 1.         | 0.74              | 6.67               | -                               |\n",
    "| Model 2.         | 0.76              | 6.61               |'state'                          |\n",
    "| Model 3.         | 0.76              | 6.63               |'state','summit_elev'|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "Model 2 is the best model since due to highest explained variance and lowest mean absolute error. Considering different characteristics and vairables that apply to each resort, it is important for Big Mountain management to be able to stick to a model that is able to predict with higest confidence what variables/ factors would drive ski resort lift ticket prices since ticket pricing in order to increase the revenue and offset for the increasing CAPEX it incurred due to addition of a new chair lift device. If you note, all 3 models are almost leading to same % confidence and the error is also somewhat in the same range. But going by the metrics as indicated in above table, Model 2 is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RtEspslPZyGY",
    "s0DokMkAZyGc",
    "2iuitnKcZyHS",
    "iAWQxougZyHW",
    "ThMTimlBZyHZ",
    "QwZ-LkjXZyHt",
    "srtXEA3N4-Y9",
    "ChVreJupZyIA",
    "zDgSSsq1ZyID",
    "I3GYKWfi5Llg",
    "pmMvrhbI-viE",
    "ZXDPkW3UZyIX",
    "Dnc_vHQLZyId",
    "daJxuJ-dZyIg",
    "mAQ-oHiPZyIn",
    "hnGOsp3mZyIp"
   ],
   "name": "GuidedCapstoneStep5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
